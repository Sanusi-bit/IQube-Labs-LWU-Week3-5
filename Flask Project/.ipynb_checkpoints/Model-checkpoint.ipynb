{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import snscrape.modules.twitter as snstweet\n",
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordcloud_gen(query):\n",
    "    stopwords = set(STOPWORDS)\n",
    "    wc = WordCloud (max_words = 250,stopwords = stopwords,\n",
    "                   width = 1500, height = 610,\n",
    "                   min_font_size = 5, max_font_size = 320,\n",
    "                   background_color = 'white').generate(tweets(query))\n",
    "    \n",
    "    image = wc.to_file(\"wordcloud.png\")\n",
    "    return image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweets(query):\n",
    "    list_of_tweets=[]\n",
    "    \n",
    "    tweet_count = 2000\n",
    "    text_query = query\n",
    "    since_date = \"2020-01-01\"\n",
    "    until_date = \"2021-03-31\"\n",
    "    os.system('snscrape --jsonl --max-results {} --since {} twitter-search \"{} until:{}\"> Jan-ENDSARS-tweets.json'.format(tweet_count, since_date, text_query, until_date))\n",
    "    scrapped_tweets = pd.read_json('Jan-ENDSARS-tweets.json', lines=True)\n",
    "    \n",
    "    list_of_tweets.append(scrapped_tweets['renderedContent'])\n",
    "    \n",
    "    df = pd.DataFrame(list_of_tweets, columns=['renderedContent'])\n",
    "    \n",
    "    def preprocess_text(text):\n",
    "        \n",
    "        #lower case\n",
    "        text = text.lower()\n",
    "    \n",
    "        #replace links with \" \"\n",
    "        text = re.sub(r\"http\\S+\", \" \", text)\n",
    "\n",
    "        #replace mentions with \" \"\n",
    "        text = re.sub(r\"@\\S+\", \" \", text)\n",
    "\n",
    "        #replace hashtags with \" \"\n",
    "        text = re.sub(r\"#\\S+\", \" \", text)\n",
    "\n",
    "        #replacing .com with \" \"\n",
    "        text = re.sub(r\".com\\S+\", \" \", text)\n",
    "\n",
    "        #dealing with contractions\n",
    "        text = re.sub(r\"won't\\S+\", \" would not\", text)\n",
    "\n",
    "        #removing space from word\n",
    "        text = [word.strip() for word in text.split()]\n",
    "\n",
    "        #removing words less than 2 characters\n",
    "        text = [word for word in text if len(word)>2]\n",
    "\n",
    "        #removing twitter amp\n",
    "        text = [word for word in text if word != 'amp']\n",
    "\n",
    "\n",
    "        text = ' '.join(text)\n",
    "        return text\n",
    "    \n",
    "    df['renderedContent'] = df['renderedContent'].apply(preprocess_text)\n",
    "    \n",
    "    tweets_corpus = ' '.join(tweet for tweet in df['renderedContent'])\n",
    "    \n",
    "    return tweets_corpus\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
